{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Define Quantized MLP in Brevitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from brevitas.nn import QuantLinear, QuantReLU, QuantIdentity\n",
    "from brevitas.core.quant import QuantType\n",
    "import torch.nn as nn\n",
    "\n",
    "class QuantizedCybSecMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedCybSecMLP, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            QuantLinear(600, 64, bias=True, weight_bit_width=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            QuantReLU(bit_width=2),\n",
    "            QuantLinear(64, 64, bias=True, weight_bit_width=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            QuantReLU(bit_width=2),\n",
    "            QuantLinear(64, 64, bias=True, weight_bit_width=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            QuantReLU(bit_width=2),\n",
    "            QuantLinear(64, 1, bias=True, weight_bit_width=2)\n",
    "        )\n",
    "        self.qnt_output = QuantIdentity(quant_type=QuantType.BINARY, bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = (x + torch.tensor([1.0])) / 2.0  \n",
    "        out_original = self.features(x)\n",
    "        out_final = self.qnt_output(out_original)\n",
    "        return out_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load dataset, measure accuracy with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brevitas_model = QuantizedCybSecMLP()\n",
    "brevitas_model.load_state_dict(torch.load(\"state_dict_export.pth\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "part_data_in = torch.from_numpy(np.load(\"unsw_nb15_binarized_inputs.npy\"))\n",
    "part_data_out = torch.from_numpy(np.load(\"unsw_nb15_binarized_outputs.npy\"))\n",
    "dataset = TensorDataset(part_data_in, part_data_out)\n",
    "test_quantized_loader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_brevitas_model_on_dataset(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            output = model(inputs.float())\n",
    "            y_pred.extend(list(output.flatten()))\n",
    "            y_true.extend(list(target.detach().numpy().flatten()))\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918075596365933"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_brevitas_model_on_dataset(brevitas_model, test_quantized_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Export to ONNX for FINN and visualize with Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n"
     ]
    }
   ],
   "source": [
    "import brevitas.onnx as bo\n",
    "\n",
    "export_onnx_path = \"cybsec-mlp-nids-demo.onnx\"\n",
    "input_shape = (1, 600)\n",
    "bo.export_finn_onnx(brevitas_model, input_shape, export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "model_file = \"cybsec-mlp-nids-demo.onnx\"\n",
    "\n",
    "model = ModelWrapper(model_file)\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType.BIPOLAR)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'cybsec-mlp-nids-demo.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff470a83b38>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"cybsec-mlp-nids-demo.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build the Quantized MLP with FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "model_file = \"cybsec-mlp-nids-demo.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"nids_demo_rtlsim\"\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    # target performance and clock frequency\n",
    "    target_fps          = 300000000,\n",
    "    synth_clk_period_ns = 3.333,\n",
    "    # target FPGA part number (for ZCU104)\n",
    "    fpga_part           = \"xczu7ev-ffvc1156-2-e\",\n",
    "    # where outputs will be written\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    # embed parameters as constants in bitstream\n",
    "    default_mem_mode    = build_cfg.ComputeEngineMemMode.CONST,\n",
    "    # enable full unfolding\n",
    "    mvau_wwidth_max     = 1000000,\n",
    "    # number of inputs for rtlsim performance measurement\n",
    "    rtlsim_perf_n_inputs = 1000,\n",
    "    # which output products to generate\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from cybsec-mlp-nids-demo.onnx\n",
      "Intermediate outputs will be generated in /data/nids-mlp-fold1\n",
      "Final outputs will be generated in nids_demo_rtlsim\n",
      "Build log is at nids_demo_rtlsim/build_dataflow.log\n",
      "Running step: step_tidy_up [1/16]\n",
      "Running step: step_streamline [2/16]\n",
      "Running step: step_convert_to_hls [3/16]\n",
      "Running step: step_create_dataflow_partition [4/16]\n",
      "Running step: step_target_fps_parallelization [5/16]\n",
      "Running step: step_apply_folding_config [6/16]\n",
      "Running step: step_generate_estimate_reports [7/16]\n",
      "Running step: step_hls_codegen [8/16]\n",
      "Running step: step_hls_ipgen [9/16]\n",
      "Running step: step_set_fifo_depths [10/16]\n",
      "Running step: step_create_stitched_ip [11/16]\n",
      "Running step: step_measure_rtlsim_performance [12/16]\n",
      "Running step: step_make_pynq_driver [13/16]\n",
      "Running step: step_out_of_context_synthesis [14/16]\n",
      "Running step: step_synthesize_bitfile [15/16]\n",
      "Running step: step_deployment_package [16/16]\n",
      "Completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build.build_dataflow_cfg(model_file, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Examine the generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_verilog_srcs.txt\t\t       ip\r\n",
      "finn_vivado_stitch_proj.cache\t       make_project.sh\r\n",
      "finn_vivado_stitch_proj.gen\t       make_project.tcl\r\n",
      "finn_vivado_stitch_proj.hw\t       vivado.jou\r\n",
      "finn_vivado_stitch_proj.ip_user_files  vivado.log\r\n",
      "finn_vivado_stitch_proj.sim\t       vivado_1314.backup.jou\r\n",
      "finn_vivado_stitch_proj.srcs\t       vivado_1314.backup.log\r\n",
      "finn_vivado_stitch_proj.xpr\t       vivado_pid28868.str\r\n"
     ]
    }
   ],
   "source": [
    "! ls {rtlsim_output_dir}/stitched_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"cycles\": 1025,\r\n",
      "  \"runtime[ms]\": 0.0034163250000000004,\r\n",
      "  \"throughput[images/s]\": 292712198.04907316,\r\n",
      "  \"DRAM_in_bandwidth[Mb/s]\": 21953.414853680486,\r\n",
      "  \"DRAM_out_bandwidth[Mb/s]\": 36.58902475613415,\r\n",
      "  \"fclk[mhz]\": 300.0300030003,\r\n",
      "  \"N\": 1000,\r\n",
      "  \"latency_cycles\": 26\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat {rtlsim_output_dir}/report/rtlsim_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Verify generated RTL model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "from finn.util.basic import gen_finn_dt_tensor\n",
    "\n",
    "rtlsim_model = ModelWrapper(rtlsim_output_dir + \"/intermediate_models/11_step_create_stitched_ip.onnx\")\n",
    "rtlsim_model.set_metadata_prop(\"exec_mode\", \"rtlsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rtlsim_model_on_dataset(model, test_loader):    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    for data in test_loader:\n",
    "        inputs, target = data\n",
    "        batch_size = inputs.shape[0]\n",
    "        model.set_tensor_shape(\"global_in\", (batch_size, 600))\n",
    "        model.set_tensor_shape(\"global_out\", (batch_size, 1))\n",
    "        output = execute_onnx(model, {\"global_in\" : inputs.float().numpy()})[\"global_out\"]\n",
    "        y_pred.extend(list(output.flatten()))\n",
    "        y_true.extend(list(target.detach().numpy().flatten()))\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918075596365933"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rtlsim_model_on_dataset(rtlsim_model, test_quantized_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
